{
  "hash": "c926d5a24ac2cb14ffed195cfc09ee7a",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Accelerate computation on Mac using PyTorch and gpu support\"\ndescription: Running a experiment using pytorch tensors on cpu vs leveraging gpu support on M1 mac and see how much gain we get in terms of speed.\nauthor: \"Vidyasagar Bhargava\"\ndate: \"8/1/2024\"\ncategories:\n  - pytorch\n---\n\n## Introduction\nIn year 2022 PyTorch and Metal engineering team at apple collaborated and announced support for GPU-accelerated pytorch operations on mac. Before that PyTorch operations on mac only leveraged CPU. But with PyTorch v1.12 release, developers and researchers can take advantage of Apple silicon GPUs for significantly faster model training as well.\nHere we will perform simple experiment to see the difference in doing tensor operations on CPU vs leveraging gpu support on M1 Mac.\n\n\n## Initial Setup\nIn order to run the experiment we need to install below libraries.\n\n```bash\n!pip install torch torchvision torchaudio\n```\n\n# Experiment\nOnce libraries are installed we can start experiment. In the experiment we will create simple PyTorch tensors and send on device `cpu` and `mps` one by one and measure the time taken to run multiplication operation.\n\nLets start with creating some tensors\n\n::: {#ce636145 .cell execution_count=1}\n``` {.python .cell-code}\nimport torch\n\n\ndef create_torch_tensors(device):\n    x = torch.rand((10000, 10000), dtype=torch.float32)\n    y = torch.rand((10000, 10000), dtype=torch.float32)\n    x = x.to(device)\n    y = y.to(device)\n\n    return x, y\n```\n:::\n\n\nmoving tensor to cpu\n\n::: {#3f4c62cf .cell execution_count=2}\n``` {.python .cell-code}\ndevice = torch.device(\"cpu\")\nx, y = create_torch_tensors(device)\n```\n:::\n\n\nMultiplying the tensors on `cpu` device.\n\n::: {#2d00f93d .cell execution_count=3}\n``` {.python .cell-code}\n%%timeit\nx * y\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n23.7 ms ± 153 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n```\n:::\n:::\n\n\nNow run the same operation using gpu of mac and see how much is improve.\n\n::: {#c6ad966b .cell execution_count=4}\n``` {.python .cell-code}\ndevice = torch.device(\"mps\")\nx, y = create_torch_tensors(device)\n```\n:::\n\n\nMultiplying the tensors on `mps` device.\n\n::: {#457f9b0b .cell execution_count=5}\n``` {.python .cell-code}\n%%timeit\nx * y\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n7.56 ms ± 18.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n```\n:::\n:::\n\n\nWe can see there is significant improvement in speed when doing tensor operation using gpu.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}