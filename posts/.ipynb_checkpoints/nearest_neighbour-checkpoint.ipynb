{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2320e3ee-7294-424c-9302-1a614d776e1f",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Nearest Neighbour Classifier\"\n",
    "description: \"Nearest neighbor classifiers are defined by their characteristic of classifying unlabeled examples by assigning them the class of similar labeled examples.\"\n",
    "author: \"Vidyasagar Bhargava\"\n",
    "date: \"06/08/2022\"\n",
    "categories:\n",
    "  - machine learning\n",
    "  - supervised learning\n",
    "  - algorithm\n",
    "  - classifier\n",
    "format:\n",
    "    html:\n",
    "        code-fold: false\n",
    "jupyter: python3\n",
    "execute: \n",
    "  enabled: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecae5309-d1fc-4246-aeae-2fa81713dbca",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/bpU9JuI.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196cd255-d786-4310-891a-ee5508b0ddff",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Nearest neighbor classifiers are defined by their characteristic of classifying unlabeled examples by assigning them the class of similar labeled examples.\n",
    "\n",
    "Nearest Neighbors works well for classification task where the relationships among the features and target classes are numerous and extremely difficult to understand but the items of similar class tend to be homogeneous.\n",
    "\n",
    "Nearest Neighbor classifier struggles most when there is no clear distinction exists among the groups.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6c622b-bd14-4f18-b68b-b1f687496103",
   "metadata": {},
   "source": [
    "# k-NN algorithm\n",
    "k-Nearest Neighbor algorithm is an example of nearest neighbor classifier.\n",
    "\n",
    "## Strength\n",
    "* Simple and effective\n",
    "* Makes no assumption about data\n",
    "* Fast Training Process\n",
    "\n",
    "\n",
    "## Weakness\n",
    "* Doesnâ€™t produce model, limiting the ability to understand how features are related to class\n",
    "* Requires selection of k\n",
    "* Slow classification phase\n",
    "* Categorical features and missing data require pre processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0365e081-c186-4607-a997-fc6af3e39cee",
   "metadata": {},
   "source": [
    "The k-Nearest Neighbor algorithm uses nearest k number of neighbors for labeling of an unlabeled example. The unlabeled test example is assigned the class of majority of the k-Nearest Neighbors.\n",
    "\n",
    "For finding the distance k-NN algorithm uses **Euclidean distance**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5779f7bd-2ff0-4630-b217-993bfc0d03e4",
   "metadata": {},
   "source": [
    "# Choosing an appropriate k\n",
    "Choosing the value of k determines how well the model will generalize to future data. Choosing a large k reduces the impact or variance caused by noisy data but can bias the learner so that it runs the risk of ignoring small, but important pattern.\n",
    "\n",
    "In Practice choosing k depends on the difficulty of the concept to be learned and the number of records in training data.\n",
    "\n",
    "* Start with k value equal to the square root of the number of training examples.\n",
    "* Using cross validation to determine the best k value.\n",
    "* Weighted voting is one of interesting way to solve this problem. By giving higher weight to close neighbors.b 444"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f3e696-4609-40f9-b79d-11e3fb67ac0b",
   "metadata": {},
   "source": [
    "# k-NN from scratch\n",
    "* Compute distances between x and all examples in the training set\n",
    "* Sort by distance and return indexes of the first k neighbors\n",
    "* Extract the labels of the k nearest neighbor training samples\n",
    "* Return the most common class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96e4e919-671c-4321-a7b0-a5dfd542319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "def euclidean_distance(x1, x2):\n",
    "        return np.sqrt(np.sum((x1 - x2)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3130728f-f035-41ae-a2d0-5cef489ab521",
   "metadata": {},
   "source": [
    "We used euclidean distance for calculating the nearest neighbors.\n",
    "\n",
    "Now we will define our KNN Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0f14048-9d7f-4be1-a5c9-04428fbfd3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        # Compute distances between x and all examples in the training set\n",
    "        distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "        # Sort by distance and return indexes of the first k neighbors\n",
    "        k_idx = np.argsort(distances)[:self.k]\n",
    "        # Extract the labels of the k nearest neighbor training samples\n",
    "        k_neighbor_labels = [self.y_train[i] for i in k_idx]  \n",
    "        # return the most common class label\n",
    "        most_common = Counter(k_neighbor_labels).most_common(1)\n",
    "        return most_common[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f88c6-af2e-4fc3-8d42-4b1d4d86048e",
   "metadata": {},
   "source": [
    "We are going to use iris dataset to test our KNN model that we created !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "242480a2-938c-4cb5-8516-d0e6b12ae63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom KNN classification accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "\n",
    "clf = KNN()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "print(\"custom KNN classification accuracy\", accuracy(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84352a8d-e2b2-4568-b9db-90658173516c",
   "metadata": {},
   "source": [
    "# k-NN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd3022d-85e8-492b-9c16-a5e5b8147932",
   "metadata": {},
   "source": [
    "## Defining the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b0d81f0-ad30-498a-9fcd-5223d7cdb785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Feature\n",
    "weather=['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny',\n",
    "'Rainy','Sunny','Overcast','Overcast','Rainy']\n",
    "# Second Feature\n",
    "temp=['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']\n",
    "\n",
    "# Label or target varible\n",
    "play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9c239f-72fb-4729-96db-e4ddaa637abc",
   "metadata": {},
   "source": [
    "We have two features weather and temperature and one label play.\n",
    "\n",
    "## Encoding data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53948aff-cc56-4e3b-8f8b-4b7c9d76e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "#creating labelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Converting string labels into numbers.\n",
    "weather_encoded=le.fit_transform(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711b5adc-ef39-4245-a1e7-ee297e996ad4",
   "metadata": {},
   "source": [
    "Similarly, you can encode temperature and label into numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "146f6545-854b-4dd5-88e2-37145fafe075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting string labels into numbers\n",
    "temp_encoded=le.fit_transform(temp)\n",
    "label=le.fit_transform(play)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e23fc88-c0e2-46f7-a196-eaa4cb5ae807",
   "metadata": {},
   "source": [
    "## Combining Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1f6517e-0e29-45e8-97c7-93f429f98d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combinig weather and temp into single listof tuples\n",
    "features=list(zip(weather_encoded,temp_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1c8e4e-fb28-481e-944d-919a139d7243",
   "metadata": {},
   "source": [
    "## Generating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e56d5c57-60fe-4086-a77e-ea69d615b426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(features,label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec12f7e8-5454-48c0-af87-2eb8ff951128",
   "metadata": {},
   "source": [
    "## Predict Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73370f28-fe52-448a-b6eb-e521997730e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "predicted= model.predict([[0,2]]) # 0:Overcast, 2:Mild\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eb8101-bffe-42b4-945f-d91b1bc92ef1",
   "metadata": {},
   "source": [
    "# k-NN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79f3254a-bc7b-481a-a7b2-c5df12610b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vidyasagar.bhargava/miniconda3/envs/databricks/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "X,y = load_boston(return_X_y=True)\n",
    "mod = KNeighborsRegressor()\n",
    "mod.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18012f02-b9ee-43e3-b116-ffe3da478189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.78, 22.9 , 25.36, 26.06, 27.1 , 27.1 , 20.88, 19.1 , 18.4 ,\n",
       "       19.48, 19.28, 22.  , 24.34, 20.52, 24.66, 21.3 , 30.48, 20.4 ,\n",
       "       15.7 , 23.54, 16.82, 17.64, 18.3 , 17.08, 16.66, 15.1 , 16.78,\n",
       "       14.94, 19.94, 18.34, 14.1 , 16.82, 15.12, 14.1 , 15.12, 26.92,\n",
       "       22.14, 27.4 , 28.44, 31.88, 31.88, 25.36, 25.36, 24.22, 20.68,\n",
       "       20.44, 20.44, 18.1 , 18.1 , 24.  , 21.54, 24.  , 27.16, 27.16,\n",
       "       25.7 , 39.82, 27.08, 38.28, 24.8 , 25.64, 21.78, 33.6 , 21.78,\n",
       "       24.06, 31.74, 25.3 , 26.98, 22.18, 20.42, 20.42, 27.76, 29.5 ,\n",
       "       27.76, 27.76, 22.92, 21.64, 25.82, 21.64, 21.38, 22.02, 24.8 ,\n",
       "       21.88, 25.22, 25.64, 25.98, 25.98, 23.28, 25.98, 24.02, 25.58,\n",
       "       25.58, 25.06, 26.34, 26.04, 30.1 , 24.84, 23.62, 24.32, 28.52,\n",
       "       24.96, 22.1 , 22.2 , 15.34, 19.74, 19.74, 19.66, 19.56, 21.34,\n",
       "       19.66, 19.56, 22.08, 20.1 , 19.6 , 17.54, 20.1 , 17.7 , 20.2 ,\n",
       "       20.1 , 20.66, 19.8 , 22.76, 20.6 , 19.66, 18.52, 19.66, 20.6 ,\n",
       "       18.52, 16.62, 18.04, 16.88, 18.4 , 18.4 , 18.78, 18.56, 20.24,\n",
       "       17.44, 17.8 , 18.4 , 15.88, 17.06, 15.24, 14.76, 15.62, 15.62,\n",
       "       15.62, 18.26, 18.26, 15.62, 17.82, 17.44, 37.22, 20.66, 19.28,\n",
       "       20.24, 20.24, 15.34, 15.34, 37.78, 25.52, 32.08, 20.66, 42.56,\n",
       "       44.54, 44.54, 30.34, 20.24, 37.22, 19.52, 19.98, 20.24, 19.98,\n",
       "       18.74, 21.9 , 24.4 , 23.74, 25.82, 22.34, 24.2 , 23.84, 38.56,\n",
       "       33.24, 38.56, 33.24, 31.6 , 33.24, 38.56, 37.84, 32.72, 33.14,\n",
       "       32.72, 33.14, 32.72, 33.72, 31.8 , 31.8 , 34.9 , 26.78, 25.24,\n",
       "       26.78, 29.38, 29.5 , 25.2 , 25.3 , 41.28, 41.28, 23.76, 23.78,\n",
       "       20.74, 22.9 , 21.1 , 21.1 , 21.1 , 23.9 , 28.84, 22.6 , 27.28,\n",
       "       22.96, 21.9 , 21.1 , 23.38, 25.42, 17.32, 31.8 , 24.46, 37.82,\n",
       "       36.46, 36.14, 35.96, 29.5 , 29.44, 34.  , 41.28, 38.28, 38.16,\n",
       "       28.12, 29.3 , 34.12, 34.12, 21.44, 21.92, 21.44, 21.4 , 22.1 ,\n",
       "       21.74, 20.  , 19.68, 22.16, 20.  , 21.38, 31.22, 31.22, 26.28,\n",
       "       29.56, 31.22, 27.08, 24.86, 38.28, 42.44, 38.9 , 36.48, 38.82,\n",
       "       41.88, 41.88, 37.9 , 41.88, 34.6 , 38.82, 36.16, 32.42, 31.74,\n",
       "       32.58, 28.82, 31.74, 26.88, 31.96, 31.96, 31.96, 31.96, 31.96,\n",
       "       30.58, 31.74, 32.58, 36.62, 42.8 , 24.84, 21.88, 38.64, 21.88,\n",
       "       24.44, 22.62, 34.9 , 34.9 , 31.88, 24.54, 23.28, 24.44, 23.22,\n",
       "       22.94, 25.28, 29.12, 25.42, 25.78, 28.02, 30.58, 31.22, 27.02,\n",
       "       31.96, 27.02, 23.72, 21.6 , 29.  , 21.32, 21.02, 20.94, 21.44,\n",
       "       21.6 , 18.54, 19.52, 20.5 , 21.3 , 23.32, 23.76, 23.32, 22.9 ,\n",
       "       22.06, 23.76, 26.14, 22.06, 19.7 , 21.22, 19.92, 21.86, 22.98,\n",
       "       23.6 , 21.16, 20.78, 25.74, 24.3 , 20.72, 22.64, 24.32, 24.44,\n",
       "       19.8 , 29.36, 26.58, 19.  , 18.84, 26.48, 33.32, 25.78, 25.78,\n",
       "       28.  , 30.46, 42.8 , 20.96, 24.8 , 15.88, 19.06, 20.94, 21.42,\n",
       "       33.8 , 25.6 , 30.94, 25.6 , 27.22, 27.22, 16.98, 14.58, 39.16,\n",
       "       39.16, 26.46, 36.6 , 27.22, 11.36, 10.54, 10.82, 12.36, 12.5 ,\n",
       "        9.6 , 10.22,  6.86, 10.26, 11.62, 11.62, 14.16, 11.  ,  8.94,\n",
       "        9.74, 13.18, 12.5 , 13.52, 21.66, 11.88, 15.58, 11.74, 13.54,\n",
       "       13.98, 12.46,  8.5 , 14.82,  9.54, 11.14, 15.88, 10.5 , 14.28,\n",
       "        6.86, 13.18, 18.56, 14.52, 17.62, 10.34, 12.74, 11.88, 17.18,\n",
       "       10.92, 11.88, 11.2 , 14.58, 11.96, 10.44, 16.98, 16.98, 14.16,\n",
       "       13.58, 12.94, 11.74, 12.56, 10.26, 13.52, 11.58, 14.  , 12.6 ,\n",
       "       13.52, 13.3 , 12.9 , 12.16, 12.1 , 10.56, 12.12, 11.96, 10.6 ,\n",
       "       14.56, 13.84, 13.34, 13.44, 12.44, 16.98, 13.34, 14.48, 16.06,\n",
       "       13.58, 15.54, 17.04, 16.62, 12.54, 12.2 , 13.58, 12.94, 14.84,\n",
       "       20.24, 14.34, 19.82, 20.24, 20.38, 22.28, 17.56, 12.74, 18.56,\n",
       "       23.7 , 21.26, 20.24, 18.6 , 22.72, 23.28, 15.54, 16.06, 14.18,\n",
       "       14.96, 15.88, 16.36, 22.28, 22.72, 23.44, 20.86, 22.8 , 21.34,\n",
       "       21.42, 21.34, 17.04, 11.54, 12.28, 14.86, 18.3 , 22.08, 21.82,\n",
       "       22.02, 18.7 , 18.7 , 20.64, 18.7 , 19.96, 21.18, 23.12, 20.88,\n",
       "       21.9 , 21.42])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ac594-2ad9-4335-b5ff-8816ea0f08f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "databricks",
   "language": "python",
   "name": "databricks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
