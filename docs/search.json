[
  {
    "objectID": "posts/eda.html",
    "href": "posts/eda.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Why EDA is important ?\nUsually we start any data science project with understanding the business problem and then we generate hypothesis. During hypothesis generation we look for factors which influence our dependent variable. EDA helps in confirming and validating those hypothesis.\nIt helps to find out unexpected pattern in data which must be taken into account, thereby suggesting some changes in planned analysis.\nIt helps in delivering data driven insights to business stakeholders by confirming they are asking the right questions and not biasing the investigation with their assumptions.\n\n\nHow to EDA\nI divide exploratory data analysis in 3 parts of investigation.\n\nStructure Investigation : Exploring shape and as well as data types.\n\nQuality Investigation : To check general quality of datasets in regard to duplicates,missing values and unwanted entries.\n\nContent Investigation : More indepth study of features and how they relate to each other.\n\n\n\nExample Case\nLet’s download some data and perform eda to bring insights as well know quality of the data.\n\nfrom sklearn.datasets import fetch_openml\n# Download the dataset from openml\ndataset = fetch_openml(data_id=42803, as_frame=True)\n\n# Extract feature matrix X and show 5 random samples\ndf_X = dataset[\"frame\"]\ndf_X\n\n\n\n\n\n  \n    \n      \n      Accident_Index\n      Vehicle_Reference_df_res\n      Vehicle_Type\n      Towing_and_Articulation\n      Vehicle_Manoeuvre\n      Vehicle_Location-Restricted_Lane\n      Junction_Location\n      Skidding_and_Overturning\n      Hit_Object_in_Carriageway\n      Vehicle_Leaving_Carriageway\n      ...\n      Age_Band_of_Casualty\n      Casualty_Severity\n      Pedestrian_Location\n      Pedestrian_Movement\n      Car_Passenger\n      Bus_or_Coach_Passenger\n      Pedestrian_Road_Maintenance_Worker\n      Casualty_Type\n      Casualty_Home_Area_Type\n      Casualty_IMD_Decile\n    \n  \n  \n    \n      0\n      201501BS70001\n      1.0\n      19.0\n      0.0\n      9.0\n      0.0\n      8.0\n      0.0\n      0.0\n      0.0\n      ...\n      7.0\n      3.0\n      5.0\n      1.0\n      0.0\n      0.0\n      2.0\n      0.0\n      NaN\n      NaN\n    \n    \n      1\n      201501BS70002\n      1.0\n      9.0\n      0.0\n      9.0\n      0.0\n      8.0\n      0.0\n      0.0\n      0.0\n      ...\n      5.0\n      3.0\n      9.0\n      9.0\n      0.0\n      0.0\n      2.0\n      0.0\n      1.0\n      3.0\n    \n    \n      2\n      201501BS70004\n      1.0\n      9.0\n      0.0\n      9.0\n      0.0\n      2.0\n      0.0\n      0.0\n      0.0\n      ...\n      6.0\n      3.0\n      1.0\n      3.0\n      0.0\n      0.0\n      2.0\n      0.0\n      1.0\n      6.0\n    \n    \n      3\n      201501BS70005\n      1.0\n      9.0\n      0.0\n      9.0\n      0.0\n      2.0\n      0.0\n      0.0\n      0.0\n      ...\n      2.0\n      3.0\n      5.0\n      1.0\n      0.0\n      0.0\n      2.0\n      0.0\n      1.0\n      2.0\n    \n    \n      4\n      201501BS70008\n      1.0\n      1.0\n      0.0\n      18.0\n      0.0\n      8.0\n      0.0\n      0.0\n      0.0\n      ...\n      8.0\n      2.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n      1.0\n      3.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      363238\n      2015984141415\n      13.0\n      9.0\n      0.0\n      18.0\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      ...\n      1.0\n      3.0\n      0.0\n      0.0\n      2.0\n      0.0\n      0.0\n      9.0\n      1.0\n      NaN\n    \n    \n      363239\n      2015984141415\n      13.0\n      9.0\n      0.0\n      18.0\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      ...\n      5.0\n      3.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      9.0\n      1.0\n      2.0\n    \n    \n      363240\n      2015984141415\n      13.0\n      9.0\n      0.0\n      18.0\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      ...\n      4.0\n      3.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      9.0\n      2.0\n      5.0\n    \n    \n      363241\n      2015984141415\n      13.0\n      9.0\n      0.0\n      18.0\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      ...\n      6.0\n      3.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      9.0\n      3.0\n      NaN\n    \n    \n      363242\n      2015984141415\n      13.0\n      9.0\n      0.0\n      18.0\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      ...\n      4.0\n      3.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      9.0\n      1.0\n      4.0\n    \n  \n\n363243 rows × 67 columns\n\n\n\n\n\nStructure Investigation\n\ndf_X.shape\n\n(363243, 67)\n\n\n\nimport pandas as pd\npd.value_counts(df_X.dtypes)\n\nfloat64    61\nobject      6\ndtype: int64\n\n\n\n\nStructure of Non Numerical Features\n\n# Display non-numerical features\ndf_X.select_dtypes(exclude=\"number\").head()\n\n\n\n\n\n  \n    \n      \n      Accident_Index\n      Sex_of_Driver\n      Date\n      Time\n      Local_Authority_(Highway)\n      LSOA_of_Accident_Location\n    \n  \n  \n    \n      0\n      201501BS70001\n      1.0\n      12/01/2015\n      18:45\n      E09000020\n      E01002825\n    \n    \n      1\n      201501BS70002\n      1.0\n      12/01/2015\n      07:50\n      E09000020\n      E01002820\n    \n    \n      2\n      201501BS70004\n      1.0\n      12/01/2015\n      18:08\n      E09000020\n      E01002833\n    \n    \n      3\n      201501BS70005\n      1.0\n      13/01/2015\n      07:40\n      E09000020\n      E01002874\n    \n    \n      4\n      201501BS70008\n      1.0\n      09/01/2015\n      07:30\n      E09000020\n      E01002814\n    \n  \n\n\n\n\n\n# Changes data type of 'Sex_of_Driver'\ndf_X[\"Sex_of_Driver\"] = df_X[\"Sex_of_Driver\"].astype(\"float\")\n\n\ndf_X.describe(exclude=\"number\")\n\n\n\n\n\n  \n    \n      \n      Accident_Index\n      Date\n      Time\n      Local_Authority_(Highway)\n      LSOA_of_Accident_Location\n    \n  \n  \n    \n      count\n      363243\n      319866\n      319822\n      319866\n      298758\n    \n    \n      unique\n      140056\n      365\n      1439\n      204\n      25979\n    \n    \n      top\n      201543P296025\n      14/02/2015\n      17:30\n      E10000017\n      E01028497\n    \n    \n      freq\n      1332\n      2144\n      2972\n      8457\n      1456\n    \n  \n\n\n\n\n\n\nStructure of Numerical Features\n\n# For each numerical feature compute number of unique entries\nunique_values = df_X.select_dtypes(include=\"number\").nunique().sort_values()\n\n# Plot information with y-axis in log-scale\nunique_values.plot.bar(logy=True, figsize=(15, 4), title=\"Unique values per feature\");\n\n\n\n\n\n\nQuality Investigation\n\n# Check number of duplicates while ignoring the index feature\nn_duplicates = df_X.drop(labels=[\"Accident_Index\"], axis=1).duplicated().sum()\nprint(f\"You seem to have {n_duplicates} duplicates in your database.\")\n\nYou seem to have 22 duplicates in your database.\n\n\n\n#  Extract column names of all features, except 'Accident_Index'\ncolumns_to_consider = df_X.drop(labels=[\"Accident_Index\"], axis=1).columns\n\n# Drop duplicates based on 'columns_to_consider'\ndf_X = df_X.drop_duplicates(subset=columns_to_consider)\ndf_X.shape\n\n(363221, 67)\n\n\n\n\nMissing Values\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 8))\nplt.imshow(df_X.isna(), aspect=\"auto\", interpolation=\"nearest\", cmap=\"gray\")\nplt.xlabel(\"Column Number\")\nplt.ylabel(\"Sample Number\");"
  },
  {
    "objectID": "posts/fbeta_measure.html",
    "href": "posts/fbeta_measure.html",
    "title": "Fbeta-Measure",
    "section": "",
    "text": "Precision is a metric that calculates the percentage of correct predictions for the positive class. Recall calculates the percentage of correct predictions for the positive class out of all positive predictions that could be made.\nThe F-measure is calculated as the harmonic mean of precision and recall, giving each the same weighting.It allows a model to be evaluated taking both the precision and recall into account using a single score, which is helpful when describing the performance of the model and in comparing models.\nThe Fbeta-measure is a generalization of the F-measure that adds a configuration parameter called beta. A default beta value is 1.0, which is the same as the F-measure. A smaller beta value, such as 0.5, gives more weight to precision and less to recall, whereas a larger beta value, such as 2.0, gives less weight to precision and more weight to recall in the calculation of the score.\nSummary\n\nPrecision and recall provide two ways to summarize the errors made for the positive class in a binary classification problem.\n\nF-measure provides a single score that summarizes the precision and recall.\n\nFbeta-measure provides a configurable version of the F-measure to give more or less attention to the precision and recall measure when calculating a single score."
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Vidyasagar Bhargava",
    "section": "",
    "text": "Lead Data Scientist at TVS Motor"
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "",
    "section": "",
    "text": "Education\n\nB.Tech in Computer Science and Engineering\n\n\n\nCourses\n\nMachine Learning Course by Andrew NG\nDeep learning Course by Andrew NG\nBig Data Foundation by IBM\nIntroduction to Python by Kaggle"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "",
    "section": "",
    "text": "Exploratory Data Analysis in short known as EDA is way of summarizing, interpreting and visualizing the information hidden in rows and column format. Simply EDA is the key to getting insights from data.\n\n\n\n\n\n\nJun 11, 2022\n\n\nVidyasagar Bhargava\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nThe Fbeta-measure is a generalization of the F-measure that adds a configuration parameter called beta\n\n\n\n\n\n\nJun 10, 2022\n\n\nVidyasagar Bhargava\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nNearest neighbor classifiers are defined by their characteristic of classifying unlabeled examples by assigning them the class of similar labeled examples.\n\n\n\n\n\n\nJun 8, 2022\n\n\nVidyasagar Bhargava\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/eda.html#exploratory-data-analysis",
    "href": "posts/eda.html#exploratory-data-analysis",
    "title": "",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\nExploratory Data Analysis in short known as EDA is way of summarizing, interpreting and visualizing the information hidden in rows and column format. Simply EDA is the key to getting insights from data.\nWhy EDA is important ?\nUsually we start any data science project with understanding the business problem and then we generate hypothesis. During hypothesis generation we look for factors which influence our dependent variable. EDA helps in confirming and validating those hypothesis.\nIt helps to find out unexpected pattern in data which must be taken into account, thereby suggesting some changes in planned analysis.\nIt helps in delivering data driven insights to business stakeholders by confirming they are asking the right questions and not biasing the investigation with their assumptions.\nStructure Investigation : Exploring shape and as well as data types\nQuality Investigation : To check general quality of datasets in regard to duplicates,missing values and unwanted entries\nContent Investigation : More indepth study of features and how they relate to each other\n\nfrom sklearn.datasets import fetch_openml\n# Download the dataset from openml\ndataset = fetch_openml(data_id=42803, as_frame=True)\n\n# Extract feature matrix X and show 5 random samples\ndf_X = dataset[\"frame\"]\ndf_X\n\n\n\n\n\n  \n    \n      \n      Accident_Index\n      Vehicle_Reference_df_res\n      Vehicle_Type\n      Towing_and_Articulation\n      Vehicle_Manoeuvre\n      Vehicle_Location-Restricted_Lane\n      Junction_Location\n      Skidding_and_Overturning\n      Hit_Object_in_Carriageway\n      Vehicle_Leaving_Carriageway\n      ...\n      Age_Band_of_Casualty\n      Casualty_Severity\n      Pedestrian_Location\n      Pedestrian_Movement\n      Car_Passenger\n      Bus_or_Coach_Passenger\n      Pedestrian_Road_Maintenance_Worker\n      Casualty_Type\n      Casualty_Home_Area_Type\n      Casualty_IMD_Decile\n    \n  \n  \n    \n      0\n      201501BS70001\n      1.0\n      19.0\n      0.0\n      9.0\n      0.0\n      8.0\n      0.0\n      0.0\n      0.0\n      ...\n      7.0\n      3.0\n      5.0\n      1.0\n      0.0\n      0.0\n      2.0\n      0.0\n      NaN\n      NaN\n    \n    \n      1\n      201501BS70002\n      1.0\n      9.0\n      0.0\n      9.0\n      0.0\n      8.0\n      0.0\n      0.0\n      0.0\n      ...\n      5.0\n      3.0\n      9.0\n      9.0\n      0.0\n      0.0\n      2.0\n      0.0\n      1.0\n      3.0\n    \n    \n      2\n      201501BS70004\n      1.0\n      9.0\n      0.0\n      9.0\n      0.0\n      2.0\n      0.0\n      0.0\n      0.0\n      ...\n      6.0\n      3.0\n      1.0\n      3.0\n      0.0\n      0.0\n      2.0\n      0.0\n      1.0\n      6.0\n    \n    \n      3\n      201501BS70005\n      1.0\n      9.0\n      0.0\n      9.0\n      0.0\n      2.0\n      0.0\n      0.0\n      0.0\n      ...\n      2.0\n      3.0\n      5.0\n      1.0\n      0.0\n      0.0\n      2.0\n      0.0\n      1.0\n      2.0\n    \n    \n      4\n      201501BS70008\n      1.0\n      1.0\n      0.0\n      18.0\n      0.0\n      8.0\n      0.0\n      0.0\n      0.0\n      ...\n      8.0\n      2.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n      1.0\n      3.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      363238\n      2015984141415\n      13.0\n      9.0\n      0.0\n      18.0\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      ...\n      1.0\n      3.0\n      0.0\n      0.0\n      2.0\n      0.0\n      0.0\n      9.0\n      1.0\n      NaN\n    \n    \n      363239\n      2015984141415\n      13.0\n      9.0\n      0.0\n      18.0\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      ...\n      5.0\n      3.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      9.0\n      1.0\n      2.0\n    \n    \n      363240\n      2015984141415\n      13.0\n      9.0\n      0.0\n      18.0\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      ...\n      4.0\n      3.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      9.0\n      2.0\n      5.0\n    \n    \n      363241\n      2015984141415\n      13.0\n      9.0\n      0.0\n      18.0\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      ...\n      6.0\n      3.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      9.0\n      3.0\n      NaN\n    \n    \n      363242\n      2015984141415\n      13.0\n      9.0\n      0.0\n      18.0\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      ...\n      4.0\n      3.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      9.0\n      1.0\n      4.0\n    \n  \n\n363243 rows × 67 columns\n\n\n\n\nStructure Investigation\n\ndf_X.shape\n\n(363243, 67)\n\n\n\nimport pandas as pd\npd.value_counts(df_X.dtypes)\n\nfloat64    61\nobject      6\ndtype: int64\n\n\n\n\nStructure of Non Numerical Features\n\n# Display non-numerical features\ndf_X.select_dtypes(exclude=\"number\").head()\n\n\n\n\n\n  \n    \n      \n      Accident_Index\n      Sex_of_Driver\n      Date\n      Time\n      Local_Authority_(Highway)\n      LSOA_of_Accident_Location\n    \n  \n  \n    \n      0\n      201501BS70001\n      1.0\n      12/01/2015\n      18:45\n      E09000020\n      E01002825\n    \n    \n      1\n      201501BS70002\n      1.0\n      12/01/2015\n      07:50\n      E09000020\n      E01002820\n    \n    \n      2\n      201501BS70004\n      1.0\n      12/01/2015\n      18:08\n      E09000020\n      E01002833\n    \n    \n      3\n      201501BS70005\n      1.0\n      13/01/2015\n      07:40\n      E09000020\n      E01002874\n    \n    \n      4\n      201501BS70008\n      1.0\n      09/01/2015\n      07:30\n      E09000020\n      E01002814\n    \n  \n\n\n\n\n\n# Changes data type of 'Sex_of_Driver'\ndf_X[\"Sex_of_Driver\"] = df_X[\"Sex_of_Driver\"].astype(\"float\")\n\n\ndf_X.describe(exclude=\"number\")\n\n\n\n\n\n  \n    \n      \n      Accident_Index\n      Date\n      Time\n      Local_Authority_(Highway)\n      LSOA_of_Accident_Location\n    \n  \n  \n    \n      count\n      363243\n      319866\n      319822\n      319866\n      298758\n    \n    \n      unique\n      140056\n      365\n      1439\n      204\n      25979\n    \n    \n      top\n      201543P296025\n      14/02/2015\n      17:30\n      E10000017\n      E01028497\n    \n    \n      freq\n      1332\n      2144\n      2972\n      8457\n      1456\n    \n  \n\n\n\n\n\n\nStructure of Numerical Features\n\n# For each numerical feature compute number of unique entries\nunique_values = df_X.select_dtypes(include=\"number\").nunique().sort_values()\n\n# Plot information with y-axis in log-scale\nunique_values.plot.bar(logy=True, figsize=(15, 4), title=\"Unique values per feature\");\n\n\n\n\n\n\nQuality Investigation\n\n# Check number of duplicates while ignoring the index feature\nn_duplicates = df_X.drop(labels=[\"Accident_Index\"], axis=1).duplicated().sum()\nprint(f\"You seem to have {n_duplicates} duplicates in your database.\")\n\nYou seem to have 22 duplicates in your database.\n\n\n\n#  Extract column names of all features, except 'Accident_Index'\ncolumns_to_consider = df_X.drop(labels=[\"Accident_Index\"], axis=1).columns\n\n# Drop duplicates based on 'columns_to_consider'\ndf_X = df_X.drop_duplicates(subset=columns_to_consider)\ndf_X.shape\n\n(363221, 67)\n\n\n\n\nMissing Values\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 8))\nplt.imshow(df_X.isna(), aspect=\"auto\", interpolation=\"nearest\", cmap=\"gray\")\nplt.xlabel(\"Column Number\")\nplt.ylabel(\"Sample Number\");\n\n\n\n\n\n\n\n\nWe know from the first fundamental theorem of calculus that for \\(x\\) in \\([a, b]\\):\n\\[\\frac{d}{dx}\\left( \\int_{a}^{x} f(u)\\,du\\right)=f(x).\\]"
  },
  {
    "objectID": "posts/Untitled.html",
    "href": "posts/Untitled.html",
    "title": "Nearest Neighbour Classifier",
    "section": "",
    "text": "Nearest neighbor classifiers are defined by their characteristic of classifying unlabeled examples by assigning them the class of similar labeled examples.\nNearest Neighbors works well for classification task where the relationships among the features and target classes are numerous and extremely difficult to understand but the items of similar class tend to be homogeneous.\nNearest Neighbor classifier struggles most when there is no clear distinction exists among the groups."
  },
  {
    "objectID": "posts/Untitled.html#strength",
    "href": "posts/Untitled.html#strength",
    "title": "Nearest Neighbour Classifier",
    "section": "Strength",
    "text": "Strength\n\nSimple and effective\nMakes no assumption about data\nFast Training Process"
  },
  {
    "objectID": "posts/Untitled.html#weakness",
    "href": "posts/Untitled.html#weakness",
    "title": "Nearest Neighbour Classifier",
    "section": "Weakness",
    "text": "Weakness\n\nDoesn’t produce model, limiting the ability to understand how features are related to class\nRequires selection of k\nSlow classification phase\nCategorical features and missing data require pre processing\n\nThe k-Nearest Neighbor algorithm uses nearest k number of neighbors for labeling of an unlabeled example. The unlabeled test example is assigned the class of majority of the k-Nearest Neighbors.\nFor finding the distance k-NN algorithm uses Euclidean distance."
  },
  {
    "objectID": "posts/Untitled.html#defining-the-dataset",
    "href": "posts/Untitled.html#defining-the-dataset",
    "title": "Nearest Neighbour Classifier",
    "section": "Defining the dataset",
    "text": "Defining the dataset\n\n# First Feature\nweather=['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny',\n'Rainy','Sunny','Overcast','Overcast','Rainy']\n# Second Feature\ntemp=['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']\n\n# Label or target varible\nplay=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']\n\nWe have two features weather and temperature and one label play."
  },
  {
    "objectID": "posts/Untitled.html#encoding-data-columns",
    "href": "posts/Untitled.html#encoding-data-columns",
    "title": "Nearest Neighbour Classifier",
    "section": "Encoding data columns",
    "text": "Encoding data columns\n\nfrom sklearn import preprocessing\n\n#creating labelEncoder\nle = preprocessing.LabelEncoder()\n\n# Converting string labels into numbers.\nweather_encoded=le.fit_transform(weather)\n\nSimilarly, you can encode temperature and label into numeric columns.\n\n# converting string labels into numbers\ntemp_encoded=le.fit_transform(temp)\nlabel=le.fit_transform(play)"
  },
  {
    "objectID": "posts/Untitled.html#combining-features",
    "href": "posts/Untitled.html#combining-features",
    "title": "Nearest Neighbour Classifier",
    "section": "Combining Features",
    "text": "Combining Features\n\n#combinig weather and temp into single listof tuples\nfeatures=list(zip(weather_encoded,temp_encoded))"
  },
  {
    "objectID": "posts/Untitled.html#generating-models",
    "href": "posts/Untitled.html#generating-models",
    "title": "Nearest Neighbour Classifier",
    "section": "Generating Models",
    "text": "Generating Models\n\nfrom sklearn.neighbors import KNeighborsClassifier\nmodel = KNeighborsClassifier(n_neighbors=3)\n\n# Train the model using the training sets\nmodel.fit(features,label)\n\nKNeighborsClassifier(n_neighbors=3)"
  },
  {
    "objectID": "posts/Untitled.html#predict-output",
    "href": "posts/Untitled.html#predict-output",
    "title": "Nearest Neighbour Classifier",
    "section": "Predict Output",
    "text": "Predict Output\n\npredicted= model.predict([[0,2]]) # 0:Overcast, 2:Mild\nprint(predicted)\n\n[1]"
  },
  {
    "objectID": "posts/nearest_neighbour.html#strength",
    "href": "posts/nearest_neighbour.html#strength",
    "title": "Nearest Neighbour Classifier",
    "section": "Strength",
    "text": "Strength\n\nSimple and effective\nMakes no assumption about data\nFast Training Process"
  },
  {
    "objectID": "posts/nearest_neighbour.html#weakness",
    "href": "posts/nearest_neighbour.html#weakness",
    "title": "Nearest Neighbour Classifier",
    "section": "Weakness",
    "text": "Weakness\n\nDoesn’t produce model, limiting the ability to understand how features are related to class\nRequires selection of k\nSlow classification phase\nCategorical features and missing data require pre processing\n\nThe k-Nearest Neighbor algorithm uses nearest k number of neighbors for labeling of an unlabeled example. The unlabeled test example is assigned the class of majority of the k-Nearest Neighbors.\nFor finding the distance k-NN algorithm uses Euclidean distance."
  },
  {
    "objectID": "posts/nearest_neighbour.html#defining-the-dataset",
    "href": "posts/nearest_neighbour.html#defining-the-dataset",
    "title": "Nearest Neighbour Classifier",
    "section": "Defining the dataset",
    "text": "Defining the dataset\n\n# First Feature\nweather=['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny',\n'Rainy','Sunny','Overcast','Overcast','Rainy']\n# Second Feature\ntemp=['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']\n\n# Label or target varible\nplay=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']\n\nWe have two features weather and temperature and one label play."
  },
  {
    "objectID": "posts/nearest_neighbour.html#encoding-data-columns",
    "href": "posts/nearest_neighbour.html#encoding-data-columns",
    "title": "Nearest Neighbour Classifier",
    "section": "Encoding data columns",
    "text": "Encoding data columns\n\nfrom sklearn import preprocessing\n\n#creating labelEncoder\nle = preprocessing.LabelEncoder()\n\n# Converting string labels into numbers.\nweather_encoded=le.fit_transform(weather)\n\nSimilarly, you can encode temperature and label into numeric columns.\n\n# converting string labels into numbers\ntemp_encoded=le.fit_transform(temp)\nlabel=le.fit_transform(play)"
  },
  {
    "objectID": "posts/nearest_neighbour.html#combining-features",
    "href": "posts/nearest_neighbour.html#combining-features",
    "title": "Nearest Neighbour Classifier",
    "section": "Combining Features",
    "text": "Combining Features\n\n#combinig weather and temp into single listof tuples\nfeatures=list(zip(weather_encoded,temp_encoded))"
  },
  {
    "objectID": "posts/nearest_neighbour.html#generating-models",
    "href": "posts/nearest_neighbour.html#generating-models",
    "title": "Nearest Neighbour Classifier",
    "section": "Generating Models",
    "text": "Generating Models\n\nfrom sklearn.neighbors import KNeighborsClassifier\nmodel = KNeighborsClassifier(n_neighbors=3)\n\n# Train the model using the training sets\nmodel.fit(features,label)\n\nKNeighborsClassifier(n_neighbors=3)"
  },
  {
    "objectID": "posts/nearest_neighbour.html#predict-output",
    "href": "posts/nearest_neighbour.html#predict-output",
    "title": "Nearest Neighbour Classifier",
    "section": "Predict Output",
    "text": "Predict Output\n\npredicted= model.predict([[0,2]]) # 0:Overcast, 2:Mild\nprint(predicted)\n\n[1]"
  },
  {
    "objectID": "posts/eda.html#how",
    "href": "posts/eda.html#how",
    "title": "Exploratory Data Analysis",
    "section": "How",
    "text": "How\nStructure Investigation : Exploring shape and as well as data types\nQuality Investigation : To check general quality of datasets in regard to duplicates,missing values and unwanted entries\nContent Investigation : More indepth study of features and how they relate to each other\n\nfrom sklearn.datasets import fetch_openml\n# Download the dataset from openml\ndataset = fetch_openml(data_id=42803, as_frame=True)\n\n# Extract feature matrix X and show 5 random samples\ndf_X = dataset[\"frame\"]\ndf_X\n\n\n\n\n\n  \n    \n      \n      Accident_Index\n      Vehicle_Reference_df_res\n      Vehicle_Type\n      Towing_and_Articulation\n      Vehicle_Manoeuvre\n      Vehicle_Location-Restricted_Lane\n      Junction_Location\n      Skidding_and_Overturning\n      Hit_Object_in_Carriageway\n      Vehicle_Leaving_Carriageway\n      ...\n      Age_Band_of_Casualty\n      Casualty_Severity\n      Pedestrian_Location\n      Pedestrian_Movement\n      Car_Passenger\n      Bus_or_Coach_Passenger\n      Pedestrian_Road_Maintenance_Worker\n      Casualty_Type\n      Casualty_Home_Area_Type\n      Casualty_IMD_Decile\n    \n  \n  \n    \n      0\n      201501BS70001\n      1.0\n      19.0\n      0.0\n      9.0\n      0.0\n      8.0\n      0.0\n      0.0\n      0.0\n      ...\n      7.0\n      3.0\n      5.0\n      1.0\n      0.0\n      0.0\n      2.0\n      0.0\n      NaN\n      NaN\n    \n    \n      1\n      201501BS70002\n      1.0\n      9.0\n      0.0\n      9.0\n      0.0\n      8.0\n      0.0\n      0.0\n      0.0\n      ...\n      5.0\n      3.0\n      9.0\n      9.0\n      0.0\n      0.0\n      2.0\n      0.0\n      1.0\n      3.0\n    \n    \n      2\n      201501BS70004\n      1.0\n      9.0\n      0.0\n      9.0\n      0.0\n      2.0\n      0.0\n      0.0\n      0.0\n      ...\n      6.0\n      3.0\n      1.0\n      3.0\n      0.0\n      0.0\n      2.0\n      0.0\n      1.0\n      6.0\n    \n    \n      3\n      201501BS70005\n      1.0\n      9.0\n      0.0\n      9.0\n      0.0\n      2.0\n      0.0\n      0.0\n      0.0\n      ...\n      2.0\n      3.0\n      5.0\n      1.0\n      0.0\n      0.0\n      2.0\n      0.0\n      1.0\n      2.0\n    \n    \n      4\n      201501BS70008\n      1.0\n      1.0\n      0.0\n      18.0\n      0.0\n      8.0\n      0.0\n      0.0\n      0.0\n      ...\n      8.0\n      2.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n      1.0\n      3.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      363238\n      2015984141415\n      13.0\n      9.0\n      0.0\n      18.0\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      ...\n      1.0\n      3.0\n      0.0\n      0.0\n      2.0\n      0.0\n      0.0\n      9.0\n      1.0\n      NaN\n    \n    \n      363239\n      2015984141415\n      13.0\n      9.0\n      0.0\n      18.0\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      ...\n      5.0\n      3.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      9.0\n      1.0\n      2.0\n    \n    \n      363240\n      2015984141415\n      13.0\n      9.0\n      0.0\n      18.0\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      ...\n      4.0\n      3.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      9.0\n      2.0\n      5.0\n    \n    \n      363241\n      2015984141415\n      13.0\n      9.0\n      0.0\n      18.0\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      ...\n      6.0\n      3.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      9.0\n      3.0\n      NaN\n    \n    \n      363242\n      2015984141415\n      13.0\n      9.0\n      0.0\n      18.0\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      ...\n      4.0\n      3.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      9.0\n      1.0\n      4.0\n    \n  \n\n363243 rows × 67 columns\n\n\n\n\nStructure Investigation\n\ndf_X.shape\n\n(363243, 67)\n\n\n\nimport pandas as pd\npd.value_counts(df_X.dtypes)\n\nfloat64    61\nobject      6\ndtype: int64\n\n\n\n\nStructure of Non Numerical Features\n\n# Display non-numerical features\ndf_X.select_dtypes(exclude=\"number\").head()\n\n\n\n\n\n  \n    \n      \n      Accident_Index\n      Sex_of_Driver\n      Date\n      Time\n      Local_Authority_(Highway)\n      LSOA_of_Accident_Location\n    \n  \n  \n    \n      0\n      201501BS70001\n      1.0\n      12/01/2015\n      18:45\n      E09000020\n      E01002825\n    \n    \n      1\n      201501BS70002\n      1.0\n      12/01/2015\n      07:50\n      E09000020\n      E01002820\n    \n    \n      2\n      201501BS70004\n      1.0\n      12/01/2015\n      18:08\n      E09000020\n      E01002833\n    \n    \n      3\n      201501BS70005\n      1.0\n      13/01/2015\n      07:40\n      E09000020\n      E01002874\n    \n    \n      4\n      201501BS70008\n      1.0\n      09/01/2015\n      07:30\n      E09000020\n      E01002814\n    \n  \n\n\n\n\n\n# Changes data type of 'Sex_of_Driver'\ndf_X[\"Sex_of_Driver\"] = df_X[\"Sex_of_Driver\"].astype(\"float\")\n\n\ndf_X.describe(exclude=\"number\")\n\n\n\n\n\n  \n    \n      \n      Accident_Index\n      Date\n      Time\n      Local_Authority_(Highway)\n      LSOA_of_Accident_Location\n    \n  \n  \n    \n      count\n      363243\n      319866\n      319822\n      319866\n      298758\n    \n    \n      unique\n      140056\n      365\n      1439\n      204\n      25979\n    \n    \n      top\n      201543P296025\n      14/02/2015\n      17:30\n      E10000017\n      E01028497\n    \n    \n      freq\n      1332\n      2144\n      2972\n      8457\n      1456\n    \n  \n\n\n\n\n\n\nStructure of Numerical Features\n\n# For each numerical feature compute number of unique entries\nunique_values = df_X.select_dtypes(include=\"number\").nunique().sort_values()\n\n# Plot information with y-axis in log-scale\nunique_values.plot.bar(logy=True, figsize=(15, 4), title=\"Unique values per feature\");\n\n\n\n\n\n\nQuality Investigation\n\n# Check number of duplicates while ignoring the index feature\nn_duplicates = df_X.drop(labels=[\"Accident_Index\"], axis=1).duplicated().sum()\nprint(f\"You seem to have {n_duplicates} duplicates in your database.\")\n\nYou seem to have 22 duplicates in your database.\n\n\n\n#  Extract column names of all features, except 'Accident_Index'\ncolumns_to_consider = df_X.drop(labels=[\"Accident_Index\"], axis=1).columns\n\n# Drop duplicates based on 'columns_to_consider'\ndf_X = df_X.drop_duplicates(subset=columns_to_consider)\ndf_X.shape\n\n(363221, 67)\n\n\n\n\nMissing Values\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 8))\nplt.imshow(df_X.isna(), aspect=\"auto\", interpolation=\"nearest\", cmap=\"gray\")\nplt.xlabel(\"Column Number\")\nplt.ylabel(\"Sample Number\");"
  },
  {
    "objectID": "posts/eda.html#how-to-eda",
    "href": "posts/eda.html#how-to-eda",
    "title": "Exploratory Data Analysis",
    "section": "How to EDA ?",
    "text": "How to EDA ?\nStructure Investigation : Exploring shape and as well as data types\nQuality Investigation : To check general quality of datasets in regard to duplicates,missing values and unwanted entries\nContent Investigation : More indepth study of features and how they relate to each other\n\nfrom sklearn.datasets import fetch_openml\n# Download the dataset from openml\ndataset = fetch_openml(data_id=42803, as_frame=True)\n\n# Extract feature matrix X and show 5 random samples\ndf_X = dataset[\"frame\"]\ndf_X\n\n\n\n\n\n  \n    \n      \n      Accident_Index\n      Vehicle_Reference_df_res\n      Vehicle_Type\n      Towing_and_Articulation\n      Vehicle_Manoeuvre\n      Vehicle_Location-Restricted_Lane\n      Junction_Location\n      Skidding_and_Overturning\n      Hit_Object_in_Carriageway\n      Vehicle_Leaving_Carriageway\n      ...\n      Age_Band_of_Casualty\n      Casualty_Severity\n      Pedestrian_Location\n      Pedestrian_Movement\n      Car_Passenger\n      Bus_or_Coach_Passenger\n      Pedestrian_Road_Maintenance_Worker\n      Casualty_Type\n      Casualty_Home_Area_Type\n      Casualty_IMD_Decile\n    \n  \n  \n    \n      0\n      201501BS70001\n      1.0\n      19.0\n      0.0\n      9.0\n      0.0\n      8.0\n      0.0\n      0.0\n      0.0\n      ...\n      7.0\n      3.0\n      5.0\n      1.0\n      0.0\n      0.0\n      2.0\n      0.0\n      NaN\n      NaN\n    \n    \n      1\n      201501BS70002\n      1.0\n      9.0\n      0.0\n      9.0\n      0.0\n      8.0\n      0.0\n      0.0\n      0.0\n      ...\n      5.0\n      3.0\n      9.0\n      9.0\n      0.0\n      0.0\n      2.0\n      0.0\n      1.0\n      3.0\n    \n    \n      2\n      201501BS70004\n      1.0\n      9.0\n      0.0\n      9.0\n      0.0\n      2.0\n      0.0\n      0.0\n      0.0\n      ...\n      6.0\n      3.0\n      1.0\n      3.0\n      0.0\n      0.0\n      2.0\n      0.0\n      1.0\n      6.0\n    \n    \n      3\n      201501BS70005\n      1.0\n      9.0\n      0.0\n      9.0\n      0.0\n      2.0\n      0.0\n      0.0\n      0.0\n      ...\n      2.0\n      3.0\n      5.0\n      1.0\n      0.0\n      0.0\n      2.0\n      0.0\n      1.0\n      2.0\n    \n    \n      4\n      201501BS70008\n      1.0\n      1.0\n      0.0\n      18.0\n      0.0\n      8.0\n      0.0\n      0.0\n      0.0\n      ...\n      8.0\n      2.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n      1.0\n      3.0\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      363238\n      2015984141415\n      13.0\n      9.0\n      0.0\n      18.0\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      ...\n      1.0\n      3.0\n      0.0\n      0.0\n      2.0\n      0.0\n      0.0\n      9.0\n      1.0\n      NaN\n    \n    \n      363239\n      2015984141415\n      13.0\n      9.0\n      0.0\n      18.0\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      ...\n      5.0\n      3.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      9.0\n      1.0\n      2.0\n    \n    \n      363240\n      2015984141415\n      13.0\n      9.0\n      0.0\n      18.0\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      ...\n      4.0\n      3.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      9.0\n      2.0\n      5.0\n    \n    \n      363241\n      2015984141415\n      13.0\n      9.0\n      0.0\n      18.0\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      ...\n      6.0\n      3.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      9.0\n      3.0\n      NaN\n    \n    \n      363242\n      2015984141415\n      13.0\n      9.0\n      0.0\n      18.0\n      0.0\n      0.0\n      0.0\n      0.0\n      5.0\n      ...\n      4.0\n      3.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      9.0\n      1.0\n      4.0\n    \n  \n\n363243 rows × 67 columns\n\n\n\n\nStructure Investigation\n\ndf_X.shape\n\n(363243, 67)\n\n\n\nimport pandas as pd\npd.value_counts(df_X.dtypes)\n\nfloat64    61\nobject      6\ndtype: int64\n\n\n\n\nStructure of Non Numerical Features\n\n# Display non-numerical features\ndf_X.select_dtypes(exclude=\"number\").head()\n\n\n\n\n\n  \n    \n      \n      Accident_Index\n      Sex_of_Driver\n      Date\n      Time\n      Local_Authority_(Highway)\n      LSOA_of_Accident_Location\n    \n  \n  \n    \n      0\n      201501BS70001\n      1.0\n      12/01/2015\n      18:45\n      E09000020\n      E01002825\n    \n    \n      1\n      201501BS70002\n      1.0\n      12/01/2015\n      07:50\n      E09000020\n      E01002820\n    \n    \n      2\n      201501BS70004\n      1.0\n      12/01/2015\n      18:08\n      E09000020\n      E01002833\n    \n    \n      3\n      201501BS70005\n      1.0\n      13/01/2015\n      07:40\n      E09000020\n      E01002874\n    \n    \n      4\n      201501BS70008\n      1.0\n      09/01/2015\n      07:30\n      E09000020\n      E01002814\n    \n  \n\n\n\n\n\n# Changes data type of 'Sex_of_Driver'\ndf_X[\"Sex_of_Driver\"] = df_X[\"Sex_of_Driver\"].astype(\"float\")\n\n\ndf_X.describe(exclude=\"number\")\n\n\n\n\n\n  \n    \n      \n      Accident_Index\n      Date\n      Time\n      Local_Authority_(Highway)\n      LSOA_of_Accident_Location\n    \n  \n  \n    \n      count\n      363243\n      319866\n      319822\n      319866\n      298758\n    \n    \n      unique\n      140056\n      365\n      1439\n      204\n      25979\n    \n    \n      top\n      201543P296025\n      14/02/2015\n      17:30\n      E10000017\n      E01028497\n    \n    \n      freq\n      1332\n      2144\n      2972\n      8457\n      1456\n    \n  \n\n\n\n\n\n\nStructure of Numerical Features\n\n# For each numerical feature compute number of unique entries\nunique_values = df_X.select_dtypes(include=\"number\").nunique().sort_values()\n\n# Plot information with y-axis in log-scale\nunique_values.plot.bar(logy=True, figsize=(15, 4), title=\"Unique values per feature\");\n\n\n\n\n\n\nQuality Investigation\n\n# Check number of duplicates while ignoring the index feature\nn_duplicates = df_X.drop(labels=[\"Accident_Index\"], axis=1).duplicated().sum()\nprint(f\"You seem to have {n_duplicates} duplicates in your database.\")\n\nYou seem to have 22 duplicates in your database.\n\n\n\n#  Extract column names of all features, except 'Accident_Index'\ncolumns_to_consider = df_X.drop(labels=[\"Accident_Index\"], axis=1).columns\n\n# Drop duplicates based on 'columns_to_consider'\ndf_X = df_X.drop_duplicates(subset=columns_to_consider)\ndf_X.shape\n\n(363221, 67)\n\n\n\n\nMissing Values\n\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 8))\nplt.imshow(df_X.isna(), aspect=\"auto\", interpolation=\"nearest\", cmap=\"gray\")\nplt.xlabel(\"Column Number\")\nplt.ylabel(\"Sample Number\");"
  }
]