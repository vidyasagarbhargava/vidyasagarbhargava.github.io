{"title":"Fbeta-Measure","markdown":{"yaml":{"title":"Fbeta-Measure","description":"A generalization of the F-measure that adds a configuration parameter called beta","author":"Vidyasagar Bhargava","date":"06/10/2022","categories":["model evaluation","precision","recall","confusion matrix"],"format":{"html":{"code-fold":false}},"jupyter":"python3","execute":{"enabled":true},"title-block-banner":true},"containsRefs":false,"markdown":"\n\n![](https://miro.medium.com/max/824/1*xMl_wkMt42Hy8i84zs2WGg.png)\n\nPrecision is a metric that calculates the percentage of correct predictions for the positive class. Recall calculates the percentage of correct predictions for the positive class out of all positive predictions that could be made. \n\n\n\nThe F-measure or F score, also called as F1 score is calculated as the harmonic mean of precision and recall, giving each the same weighting.It allows a model to be evaluated taking both the precision and recall into account using a single score, which is helpful when describing the performance of the model and in comparing models.\n\n::: {.column-margin}\n$$\nF_{1}=2.\\frac{{precision} \\times {recall}}{{precision} + {recall}}\n$$\n:::\n\nThe Fbeta-measure is a generalization of the F-measure that adds a configuration parameter called beta. A default beta value is 1.0, which is the same as the F-measure. A smaller beta value, such as 0.5, gives more weight to precision and less to recall, whereas a larger beta value, such as 2.0, gives less weight to precision and more weight to recall in the calculation of the score. \n\n\n::: {.column-margin}\n$$ \nF_{{\\beta}} = \\frac{(1 + {\\beta}^2). (precision.recall)}{({\\beta}^2.precision+recall)}\n$$\n:::\n\n**Summary**\n\n* Precision and recall provide two ways to summarize the errors made for the positive class in a binary classification problem.  \n* F-measure provides a single score that summarizes the precision and recall.  \n* Fbeta-measure provides a configurable version of the F-measure to give more or less attention to the precision and recall measure when calculating a single score.\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":true,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"output-file":"fbeta_measure.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"0.9.518","mainfont":"system-ui","fontsize":"85%","theme":["journal","../theme.scss"],"backgroundcolor":"#e6ddde","title":"Fbeta-Measure","description":"A generalization of the F-measure that adds a configuration parameter called beta","author":"Vidyasagar Bhargava","date":"06/10/2022","categories":["model evaluation","precision","recall","confusion matrix"],"jupyter":"python3","title-block-banner":true},"extensions":{"book":{"multiFile":true}}}}}