{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Alexnet\"\n",
    "\n",
    "description: AlexNet is the first deep architecture which was introduced by **Alex Krizhevsky** and his colleagues in 2012. It was designed to classify images for the ImageNet LSVRC-2010 competition where it achieved state of the art results. It is a simple yet powerful network architecture, which helped pave the way for groundbreaking research in Deep Learning as it is now.You can read more about the model in original research paper [here](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf?ref=blog.paperspace.com)\n",
    "author: \"Vidyasagar Bhargava\"\n",
    "date: \"05/12/2022\"\n",
    "categories:\n",
    "  - deep learning\n",
    "  - convolutional neural network\n",
    "  - CIFAR10\n",
    "  \n",
    "image: \"https://raw.githubusercontent.com/blurred-machine/Data-Science/master/Deep%20Learning%20SOTA/img/alexnet2.png\"\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "Unlike LeNet-5 the famous Alexnet network was operated with 3-channel images which were (224x224x3) in size. It also used max pooling with ReLU activations when subsampling. The kernels used for convolutions were either 11x11, 5x5, or 3x3 while kernels used for max pooling were 3x3 in size. It classified images into 1000 classes. It also utilized multiple GPUs.\n",
    "\n",
    "![](https://raw.githubusercontent.com/blurred-machine/Data-Science/master/Deep%20Learning%20SOTA/img/alexnet2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "### Dataset\n",
    "Let's start by loading and then pre-processing the data. For our purposes, we will be using the CIFAR10 dataset. The dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "Classes in the dataset are completely mututally exclusive. There is no overlap.  \n",
    "![](https://blog.paperspace.com/content/images/2022/04/Screenshot-2022-04-30-111638.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing the libraries\n",
    "Let's start by importing the required libraries along with defining a variable device, so that the Notebook knows to use a GPU to train the model if it's available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
