[
  {
    "objectID": "posts/Fbeta-Measure/index.html",
    "href": "posts/Fbeta-Measure/index.html",
    "title": "Fbeta-Measure",
    "section": "",
    "text": "\\[\nF_{1}=2.\\frac{{precision} \\times {recall}}{{precision} + {recall}}\n\\]\nThe Fbeta-measure is a generalization of the F-measure that adds a configuration parameter called beta. A default beta value is 1.0, which is the same as the F-measure. A smaller beta value, such as 0.5, gives more weight to precision and less to recall, whereas a larger beta value, such as 2.0, gives less weight to precision and more weight to recall in the calculation of the score.\n\n\n\\[\nF_{{\\beta}} = \\frac{(1 + {\\beta}^2). (precision.recall)}{({\\beta}^2.precision+recall)}\n\\]\nSummary\n\nPrecision and recall provide two ways to summarize the errors made for the positive class in a binary classification problem.\n\nF-measure provides a single score that summarizes the precision and recall.\n\nFbeta-measure provides a configurable version of the F-measure to give more or less attention to the precision and recall measure when calculating a single score."
  },
  {
    "objectID": "posts/Exploratory-Data-Analysis/index.html",
    "href": "posts/Exploratory-Data-Analysis/index.html",
    "title": "The Google’s Guide to Exploratory Data Analysis",
    "section": "",
    "text": "How to EDA\nI divide exploratory data analysis in 3 parts of investigation.\n\nStructure Investigation : Exploring shape and as well as data types.\n1.1 Structure of non numerical features\n1.2 Structure of numerical features\n1.3 Conclusion of structure investigation\n\nQuality Investigation : To check general quality of datasets in regard to duplicates,missing values and unwanted entries.\n2.1 Duplicates\n2.2 Missing Values\n2.2.1 Per sample\n2.2.2 Per feature\n2.3 Unwanted Entries and Recording Errors\n2.3.1 Numerical features\n2.3.2 Non Numerical features\n2.4 Conclusion of Quality Investigation\nContent Investigation : More indepth study of features and how they relate to each other. 3.1 Feature distribution\n3.2 Feature patterns\n3.2.1 Continuos feature\n3.2.2 Discreet and ordinal feature\n3.3 Feature relantionship\n\n\n\nExample Case\nLet’s download some data and perform eda to bring insights as well know quality of the data.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.datasets import fetch_openml\n\n# Download the dataset from openml\ndataset = fetch_openml(data_id=42803, as_frame=True)\n\n# Extract feature matrix X and show 5 random samples\ndf_X = dataset[\"frame\"]\ndf_X.head(5)\n\n\n\n\n\n  \n    \n      \n      Accident_Index\n      Vehicle_Reference_df_res\n      Vehicle_Type\n      Towing_and_Articulation\n      Vehicle_Manoeuvre\n      Vehicle_Location-Restricted_Lane\n      Junction_Location\n      Skidding_and_Overturning\n      Hit_Object_in_Carriageway\n      Vehicle_Leaving_Carriageway\n      ...\n      Age_Band_of_Casualty\n      Casualty_Severity\n      Pedestrian_Location\n      Pedestrian_Movement\n      Car_Passenger\n      Bus_or_Coach_Passenger\n      Pedestrian_Road_Maintenance_Worker\n      Casualty_Type\n      Casualty_Home_Area_Type\n      Casualty_IMD_Decile\n    \n  \n  \n    \n      0\n      201501BS70001\n      1.0\n      19.0\n      0.0\n      9.0\n      0.0\n      8.0\n      0.0\n      0.0\n      0.0\n      ...\n      7.0\n      3.0\n      5.0\n      1.0\n      0.0\n      0.0\n      2.0\n      0.0\n      NaN\n      NaN\n    \n    \n      1\n      201501BS70002\n      1.0\n      9.0\n      0.0\n      9.0\n      0.0\n      8.0\n      0.0\n      0.0\n      0.0\n      ...\n      5.0\n      3.0\n      9.0\n      9.0\n      0.0\n      0.0\n      2.0\n      0.0\n      1.0\n      3.0\n    \n    \n      2\n      201501BS70004\n      1.0\n      9.0\n      0.0\n      9.0\n      0.0\n      2.0\n      0.0\n      0.0\n      0.0\n      ...\n      6.0\n      3.0\n      1.0\n      3.0\n      0.0\n      0.0\n      2.0\n      0.0\n      1.0\n      6.0\n    \n    \n      3\n      201501BS70005\n      1.0\n      9.0\n      0.0\n      9.0\n      0.0\n      2.0\n      0.0\n      0.0\n      0.0\n      ...\n      2.0\n      3.0\n      5.0\n      1.0\n      0.0\n      0.0\n      2.0\n      0.0\n      1.0\n      2.0\n    \n    \n      4\n      201501BS70008\n      1.0\n      1.0\n      0.0\n      18.0\n      0.0\n      8.0\n      0.0\n      0.0\n      0.0\n      ...\n      8.0\n      2.0\n      0.0\n      0.0\n      0.0\n      0.0\n      0.0\n      1.0\n      1.0\n      3.0\n    \n  \n\n5 rows × 67 columns\n\n\n\n\n\nStructure Investigation\n\ndf_X.shape\n\n(363243, 67)\n\n\n\nimport pandas as pd\npd.value_counts(df_X.dtypes)\n\nfloat64    61\nobject      6\ndtype: int64\n\n\n\n\nStructure of Non Numerical Features\n\n# Display non-numerical features\ndf_X.select_dtypes(exclude=\"number\").head()\n\n\n\n\n\n  \n    \n      \n      Accident_Index\n      Sex_of_Driver\n      Date\n      Time\n      Local_Authority_(Highway)\n      LSOA_of_Accident_Location\n    \n  \n  \n    \n      0\n      201501BS70001\n      1.0\n      12/01/2015\n      18:45\n      E09000020\n      E01002825\n    \n    \n      1\n      201501BS70002\n      1.0\n      12/01/2015\n      07:50\n      E09000020\n      E01002820\n    \n    \n      2\n      201501BS70004\n      1.0\n      12/01/2015\n      18:08\n      E09000020\n      E01002833\n    \n    \n      3\n      201501BS70005\n      1.0\n      13/01/2015\n      07:40\n      E09000020\n      E01002874\n    \n    \n      4\n      201501BS70008\n      1.0\n      09/01/2015\n      07:30\n      E09000020\n      E01002814\n    \n  \n\n\n\n\n\n# Changes data type of 'Sex_of_Driver'\ndf_X[\"Sex_of_Driver\"] = df_X[\"Sex_of_Driver\"].astype(\"float\")\n\n\ndf_X.describe(exclude=\"number\")\n\n\n\n\n\n  \n    \n      \n      Accident_Index\n      Date\n      Time\n      Local_Authority_(Highway)\n      LSOA_of_Accident_Location\n    \n  \n  \n    \n      count\n      363243\n      319866\n      319822\n      319866\n      298758\n    \n    \n      unique\n      140056\n      365\n      1439\n      204\n      25979\n    \n    \n      top\n      201543P296025\n      14/02/2015\n      17:30\n      E10000017\n      E01028497\n    \n    \n      freq\n      1332\n      2144\n      2972\n      8457\n      1456\n    \n  \n\n\n\n\n\n\nStructure of Numerical Features\n\n# from matplotlib.offsetbox import AnnotationBbox, OffsetImage\n# import matplotlib.image as mpimg\n# def insert_image(path, zoom, xybox, ax):\n#     '''Insert an image within matplotlib'''\n#     imagebox = OffsetImage(mpimg.imread(path), zoom=zoom)\n#     ab = AnnotationBbox(imagebox, xy=(0.5, 0.7), frameon=False, pad=1, xybox=xybox)\n#     ax.add_artist(ab)\n\n\n\n# For each numerical feature compute number of unique entries\nsns.set(rc={'axes.facecolor':'#e6ddde', 'figure.facecolor':'#e6ddde'})\n\nfig, ax = plt.subplots(figsize=(10, 8))\n\nunique_values = df_X.select_dtypes(include=\"number\").nunique().sort_values()\n\n# Plot information with y-axis in log-scale\nunique_values.plot.bar(logy=True, figsize=(15, 4), title=\"Unique values per feature\",  color='#753742');\n\n\n\n\n\n\nQuality Investigation\n\n# Check number of duplicates while ignoring the index feature\nn_duplicates = df_X.drop(labels=[\"Accident_Index\"], axis=1).duplicated().sum()\nprint(f\"You seem to have {n_duplicates} duplicates in your database.\")\n\nYou seem to have 22 duplicates in your database.\n\n\n\n#  Extract column names of all features, except 'Accident_Index'\ncolumns_to_consider = df_X.drop(labels=[\"Accident_Index\"], axis=1).columns\n\n# Drop duplicates based on 'columns_to_consider'\ndf_X = df_X.drop_duplicates(subset=columns_to_consider)\ndf_X.shape\n\n(363221, 67)\n\n\nYou can check this link for guide\n\n\n\n\nA comment in the margin"
  }
]